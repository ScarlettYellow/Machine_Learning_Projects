{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.数据预处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# create feature list\n",
    "column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', \n",
    "'Uniformity of Cell Shape', 'Marginal Adhesion','Single Epithelical Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv('/Users/scarlett/repository/projects/breast_cancer/breast_cancer.csv',names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 683 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "Sample code number              683 non-null int64\n",
      "Clump Thickness                 683 non-null int64\n",
      "Uniformity of Cell Size         683 non-null int64\n",
      "Uniformity of Cell Shape        683 non-null int64\n",
      "Marginal Adhesion               683 non-null int64\n",
      "Single Epithelical Cell Size    683 non-null int64\n",
      "Bare Nuclei                     683 non-null object\n",
      "Bland Chromatin                 683 non-null int64\n",
      "Normal Nucleoli                 683 non-null int64\n",
      "Mitoses                         683 non-null int64\n",
      "Class                           683 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 64.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "data = data.replace(to_replace='?', value=np.nan)\n",
    "data = data.dropna(how='any')\n",
    "print data.shape\n",
    "print data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于原始数据没有提供对应的测试样本，故需要对带有label的样本进行分割，一般是25%作为测试集，75%作为训练集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.准备训练、测试数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    344\n",
      "4    168\n",
      "Name: Class, dtype: int64\n",
      "2    100\n",
      "4     71\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# prepare training set and testing set\n",
    "\n",
    "# use train_test_split in sklearn to split data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# randomly sample 25% for testing,75% for training\n",
    "X_train,X_test,y_train,y_test = train_test_split(data[column_names[1:10]],data[column_names[10]],test_size=0.25,random_state=33)\n",
    "\n",
    "# check number and class\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练样本：512条（344条良性肿瘤数据+168恶性肿瘤数据），测试样本171条（100+71）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn.model_selection.train_test_split解释**\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "一般形式：X_train,X_test, y_train, y_test = cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)\n",
    "\n",
    "参数解释：\n",
    "\n",
    "- train_data：所要划分的样本特征集\n",
    "- train_target：所要划分的样本结果\n",
    "- test_size：样本占比，如果是整数的话就是样本的数量\n",
    "- random_state：是随机数的种子\n",
    "\n",
    "> 随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。\n",
    "\n",
    "> 随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：\n",
    "\n",
    "> 种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.使用线性分类模型进行分类预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 4 4 2 2 2 4 2 2 2 2 4 2 4 4 4 4 4 2 2 4 4 2 4 4 2 2 4 4 4 4 4 4 4 4 2\n",
      " 4 4 4 4 4 2 4 2 2 4 2 2 4 4 2 2 2 4 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 2 2 2 4 2 2 2 4 2 4 2 4 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 2 4\n",
      " 2 2 2 2 2 2 4 2 2 4 4 2 4 2 2 2 4 2 2 4 4 2 4 4 2 2 2 2 4 2 4 2 4 2 2 2 2\n",
      " 2 4 4 2 4 4 2 4 2 2 2 2 4 4 4 2 4 2 2 4 2 4 4]\n",
      "[2 2 4 4 2 2 2 4 2 2 2 2 4 2 4 4 4 4 4 2 2 4 4 2 4 4 2 2 4 4 4 4 4 4 4 4 2\n",
      " 4 4 4 4 4 2 4 2 2 4 2 2 4 4 2 2 2 4 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 4 2 2 2\n",
      " 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 4 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 2 4\n",
      " 2 2 2 2 2 2 4 2 2 4 4 2 4 2 2 2 4 2 2 4 4 2 4 4 2 2 2 2 4 2 4 2 4 2 2 2 2\n",
      " 2 4 4 2 4 4 2 4 2 2 2 2 4 4 4 2 4 2 2 4 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# standarlize data,make sure DE=1,EX=0,so that the outcome wont be influenced by big feature\n",
    "ss = StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)\n",
    "\n",
    "# init logisticregression and SGDClassifier\n",
    "lr = LogisticRegression()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "# use fit() of LR to train paras\n",
    "lr.fit(X_train,y_train)\n",
    "# use trained lr to predict X_test\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "\n",
    "# use fit() of SGDC to train paras, use trained lr to predict X_test\n",
    "sgdc.fit(X_train,y_train)\n",
    "sgdc_y_predict=sgdc.predict(X_test)\n",
    "\n",
    "print sgdc_y_predict\n",
    "print lr_y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混淆矩阵：\n",
    "二分类任务中，预测结果(predicted condition)与正确标记(true condition)之间存在4种不同的组合：\n",
    "\n",
    "- 真阳性(true positive)：预测正确的恶性肿瘤\n",
    "- 真阴性\n",
    "- 假阳性(false positive)：误判为恶性肿瘤\n",
    "- 假阴性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.性能评价**\n",
    "\n",
    "**性能评价指标**\n",
    "\n",
    "评价指标1：准确率\n",
    "\n",
    "$ Accuracy = \\frac{TP + TN}{TP+TN+FP+FN}$\n",
    "\n",
    "评价指标2：召回率(Recall)和精确率(Precision),F1 指标(F1 measure)\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP+FP} $$\n",
    "$$ Recall = \\frac{TP}{TP+FN}$$\n",
    "$$ F1 measure = \\frac{2}{\\frac{1}{Precision}+\\frac{1}{Recall}}$$ \n",
    "\n",
    "F1指标：两指标的调和平均数，以综合考量两指标\n",
    "\n",
    "对肿瘤识别，我们更关心召回率，即应该被正确识别的恶性肿瘤的百分比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用线性分类模型进行肿瘤预测任务的性能分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy of SDG Classifier: 0.9824561403508771\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.99      0.99      0.99       100\n",
      "  Malignant       0.99      0.99      0.99        71\n",
      "\n",
      "avg / total       0.99      0.99      0.99       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 使用逻辑回归模型自带的评分函数score获得模型在测试集上的准确性结果\n",
    "print 'Acurracy of LR Classifier:', lr.score(X_test,y_test)\n",
    "# use classification_report to get the other 3 measures of LR\n",
    "print classification_report(y_test,lr_y_predict,target_names=['Benign','Malignant'])\n",
    "\n",
    "# 使用随机梯度下降模型自带的score评分函数模型在测试集上的准确性结果\n",
    "print 'Acurracy of SDG Classifier:', sgdc.score(X_test,y_test)\n",
    "# use classification_report to get the other 3 measures of SGDC\n",
    "print classification_report(y_test,lr_y_predict,target_names=['Benign','Malignant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，发现，LR比SGDC在测试集上有更高的准确性，因为sklearn中采用解析的方式精确计算LR的参数，而使用梯度法估计SGDC的参数\n",
    "\n",
    "特点分析：\n",
    "\n",
    "- LR model：精确解析参数，计算时间长但模型性能略高\n",
    "- SGDC model：随机梯度上升算法估计参数，计算时间短但模型性能略低\n",
    "- 训练数据规模在10万量级以上的数据，考虑到时间耗用，推荐使用随机梯度算法对模型参数进行估计"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
