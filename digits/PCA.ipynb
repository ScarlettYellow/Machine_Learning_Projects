{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.显示手写体数字图片经PCA压缩后的二维空间分布**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "digits_train=pd.read_csv('/Users/scarlett/repository/projects/digits/optdigits.tra',header=None)\n",
    "digits_test=pd.read_csv('/Users/scarlett/repository/projects/digits/optdigits.tes',header=None)\n",
    "\n",
    "# 分割训练数据的特征向量和标记，前64维是feature vector，第65维是标记\n",
    "X_digits=digits_train[np.arange(64)]\n",
    "y_digits=digits_train[64]\n",
    "\n",
    "# 导入PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# 初始化一个可将高维向量压缩到二维的PCA\n",
    "estimator=PCA(n_components=2)\n",
    "X_pca=estimator.fit_transform(X_digits)\n",
    "\n",
    "# 显示10类图像经PCA压缩后的二维空间分布\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_pca_scatter():\n",
    "    \n",
    "    colors=['black','blue','purple','yellow','white','red','lime','cyan','orange','gray']\n",
    "    \n",
    "    for i in xrange(len(colors)):\n",
    "        px=X_pca[:,0][y_digits.as_matrix()==i]\n",
    "        py=X_pca[:,1][y_digits.as_matrix()==i]\n",
    "        plt.scatter(px,py,c=colors[i])\n",
    "    \n",
    "    plt.legend(np.arange(0,10).astype(str))\n",
    "    plt.xlabel('First Principle Component')\n",
    "    plt.ylabel('Second Principle Component')\n",
    "    plt.show()\n",
    "    plt_pca_scatter()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.使用原始像素特征和经PCA压缩重建的低维特征，在相同配置的SVM上分别进行图像识别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 8 9 8] [0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "X_train=digits_train[np.arange(64)]\n",
    "y_train=digits_train[64]\n",
    "X_test=digits_test[np.arange(64)]\n",
    "y_test=digits_test[64]\n",
    "\n",
    "# 导入基于线性核的SVM分类器,建模，预测\n",
    "from sklearn.svm import LinearSVC\n",
    "svc=LinearSVC()\n",
    "svc.fit(X_train,y_train)\n",
    "y_predict=svc.predict(X_test)\n",
    "\n",
    "# 特征压缩到20维,并转化原训练特征\n",
    "estimator=PCA(n_components=20)\n",
    "pca_X_train=estimator.fit_transform(X_train)\n",
    "pca_X_test=estimator.transform(X_test)\n",
    "\n",
    "# 对压缩后的20维特征的训练数据进行建模，并对测试集预测\n",
    "pca_svc=LinearSVC()\n",
    "pca_svc.fit(pca_X_train,y_train)\n",
    "pca_y_predict=pca_svc.predict(pca_X_test)\n",
    "\n",
    "print pca_y_predict,y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.性能评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9309961046188091\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       178\n",
      "          1       0.85      0.95      0.90       182\n",
      "          2       0.99      0.97      0.98       177\n",
      "          3       0.92      0.95      0.93       183\n",
      "          4       0.95      0.97      0.96       181\n",
      "          5       0.90      0.96      0.93       182\n",
      "          6       0.99      0.98      0.99       181\n",
      "          7       0.98      0.91      0.94       179\n",
      "          8       0.96      0.74      0.83       174\n",
      "          9       0.82      0.91      0.86       180\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1797\n",
      "\n",
      "0.9081803005008348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.96       178\n",
      "          1       0.80      0.91      0.85       182\n",
      "          2       0.96      0.94      0.95       177\n",
      "          3       0.96      0.91      0.94       183\n",
      "          4       0.94      0.96      0.95       181\n",
      "          5       0.86      0.97      0.91       182\n",
      "          6       0.98      0.96      0.97       181\n",
      "          7       0.96      0.88      0.92       179\n",
      "          8       0.82      0.83      0.83       174\n",
      "          9       0.87      0.75      0.80       180\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print svc.score(X_test,y_test)\n",
    "print classification_report(y_test,y_predict,target_names=np.arange(10).astype(str))\n",
    "\n",
    "print pca_svc.score(pca_X_test,y_test)\n",
    "print classification_report(y_test,pca_y_predict,target_names=np.arange(10).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上发现，经过PCA处理后会损失2%左右的预测准确性，但相比原始数据64维度的特征，使用PCA可降低68.75%的维度、\n",
    "\n",
    "特点分析：\n",
    "\n",
    "- 降维/压缩是选取数据具有代表性的特征，在保持数据多样性(Variance)的基础上，规避掉大量的特征冗余和噪声；并可节省模型训练时间，提高综合效率\n",
    "- 但容易损失一些有用的模式信息"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
